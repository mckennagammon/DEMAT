{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4342ac01",
   "metadata": {},
   "source": [
    "# Twitter Text Report\n",
    "### McKenna Gammon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f18b5fbd",
   "metadata": {},
   "source": [
    "#### Overview\n",
    "I was unable to get my developer account approved in time. However, the topic I chose to pursue for this assignment is sentiments of Twitter users towards a new album being released.  driving question behind my topic for this assignment was is the overall, general sentiment of the general public (Twitter users in this case) positive or negative for a new album that was just released. This connects to the data that would be collected and used here, from my Twitter Developer Account through a Twitter API, because Twitter users say a lot of their opinions in the limited character messages they send out on the daily. There is a lot of data generated by Twitter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da7ace80",
   "metadata": {},
   "source": [
    "#### Data Structure\n",
    "The data requested from the Twitter API comes in as text that includes fields or variables such as: username, author_id, and more. We then restructure the data into a dictionary and get the keys of that dictionary. This dictionary is then formatted into a data frame using pandas. In the data frame(s), the variables such as the previously mentioned ones become names of columns of data. An addition of a new field relevant to the selected topic for the assignment was also included. By formatting the data frame as exemplified, we can then use this data frame to append future responses. After the data was successfully collected, the data frame created is exported as a CSV."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17472ccd",
   "metadata": {},
   "source": [
    "#### Data Collection and DataFrame\n",
    "The data collection process that took place was to come up with a topic of interest to use for this assignment and then apply for a Twitter Developer account in order to be approved to access a Twitter API, which is the specific tool used to collect the data. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcdd60aa",
   "metadata": {},
   "source": [
    "#### Visualization\n",
    "The data is gathered from the Twitter API, first shown as a dictionary which is then turned into a data frame using pandas. The keys from the dictionary are identified and then used in the Data Frame to organize the data into a visual representation."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36e5430",
   "metadata": {},
   "source": [
    "#### Quality, Weaknesses, and Limitations\n",
    "\n",
    "I think that the quality of the data is good here. I thought it was really interesting to use API's in a class assignment because I worked a lot with API's over the summer for my internship and continue to work with them in the position I hold now. I think using data collected from an API, like the Twitter API utilized for this assignment, is an effective approach to gather pretty reliable data if it's used to do things like the things we did here. \n",
    "\n",
    "I recognized some weaknesses after reflecting on the assignment. One weakness I thought of was some doubt that this would realistically be the best way to uncover the sentiment of general listeners towards a new album that has just dropped. There are probably better suited data collection techniques and data sets to be considered for the purpose of drawing conclusions on the publics feelings towards new music albums.\n",
    "\n",
    "The first limitation that could apply to this data set, data collection, results, and assignment is kind of along the lines of the first weakness that I recognized previously. As mentioned, this data set probably isn't the best to collect sentiments of new albums being released. So, that limits how accurately and/or how far one could potentially research this specific subject just using data collected from a Twitter API."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37ec9f23",
   "metadata": {},
   "source": [
    "#### Alternative Approaches and Potential Next Steps\n",
    "Some alternative approaches and potential next steps may be to further analyze the results. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66f17bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import urllib\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "da1e070d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Aug31_inclass_practice.ipynb   Twitter Text Report.ipynb\r\n",
      "Likes Report.ipynb             Untitled.ipynb\r\n",
      "Montero                        Untitled1.ipynb\r\n",
      "Oct-19-In-Class.ipynb          Untitled2.ipynb\r\n",
      "October 5 - Twitter API.ipynb  Untitled3.ipynb\r\n",
      "October-7-in-class.ipynb       Untitled4.ipynb\r\n",
      "Sept 7 - In-Class 2.ipynb      bls_data.csv\r\n",
      "Sept. 7 - In-Class.ipynb       chinook.db\r\n",
      "Sept.30_in_class.ipynb         sept-28.ipynb\r\n",
      "Spotify_API_Knight.ipynb\r\n"
     ]
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd92aa5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token = pd.read_csv('.txt file', sep = '\\t', header = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "beca150c",
   "metadata": {},
   "source": [
    "^ need to figure out what this .txt file is (Twitter keys?)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df2c8fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "header = {'Authorization' : 'Bearer {}'.format(bearer_token['Bearer_Token'].iloc[0])}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b671525",
   "metadata": {},
   "outputs": [],
   "source": [
    "bearer_token.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "eae2abf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_url = 'https://api.twitter.com/2/tweets/search/recent'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5400d035",
   "metadata": {},
   "outputs": [],
   "source": [
    "query = urllib.parse.quote(' - - - ')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d4afbea",
   "metadata": {},
   "source": [
    "^ need to wait for response from endpoint_url to put second line in parentheses above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2f1c512",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_api_url = endpoint_url + '?query={}'.format(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ff7c7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_api_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73c5dc27",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_fields = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b0a7cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "slightly_more_complex_api_url = endpoint_url + '?query={}&tweet.fields={}'.format(query, tweet_fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3c3c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "slightly_more_complex_api_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b1e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "expansions = 'author_id'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a922405",
   "metadata": {},
   "outputs": [],
   "source": [
    "expansions_api_url = endpoint_url + '?query={}&max_results=10&tweet.fields={}&expansions={}&user.fields={}'.format(query, tweet_fields, expansions, 'username')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f620b44d",
   "metadata": {},
   "outputs": [],
   "source": [
    "expansions_api_url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31aa01d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1 = requests.request(\"GET\", expansions_api_url, headers = header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640dd0bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdb2cc6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1_dict = json.loads(response_1.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e96c9048",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1_dict.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "895f6561",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = pd.DataFrame(response_1_dict['data'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50ae3f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24c78027",
   "metadata": {},
   "outputs": [],
   "source": [
    "# my_df.to_csv(\"twitter_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dbe8c75",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_1_dict['meta']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd8c6d8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "expansions_api_url_2 = expansions_api_url + '&next_token={}'.format(response_1_dict['meta']['next_token'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e39f010",
   "metadata": {},
   "outputs": [],
   "source": [
    "expansions_api_url _2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836c8e4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2 = requests.request(\"GET\", expansions_api_url_2, headers = header)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93dc09a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "response_2.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b789038",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = my_df.append(pd.DataFrame(json.loads(response_2.text)['data']), ignore_index= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f3087db",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df.tail(3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
